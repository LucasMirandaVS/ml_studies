{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasMirandaVS/ml_studies/blob/main/lab_jupyter_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b550f2f5-75a4-4d33-8f58-036c8a6c0e05"
      },
      "source": [
        "# **K Nearest Neighbor**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d06954c-3229-4d58-af39-0ffaf58648d2"
      },
      "source": [
        "Estimated time needed: **30** minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41d1a3ec-8dcc-4aa7-b031-2e31a27a3f83"
      },
      "source": [
        "In this lab, you will learn about and practice the K Nearest Neighbor (KNN) model. KNN is a straightforward but very effective model that can be used for both classification and regression tasks. If the feature space is not very large, KNN can be a high-interpretable model because you can explain and understand how a prediction is made by looking at its nearest neighbors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59f2da36-dd98-4c0f-8264-e700d73015ea"
      },
      "source": [
        "We will be using a tumor sample dataset containing lab test results about tumor samples. The objective is to classify whether a tumor is malicious (cancer) or benign. As such, it is a typical binary classification task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9095f1c6-e34f-406d-9603-d833cff623d9"
      },
      "source": [
        "## Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7c6c326-9744-4802-a5c4-dfb2d3f98c9d"
      },
      "source": [
        "After completing this lab, you will be able to:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da1f6ab-df5e-4e6d-94b5-c961adc9d94a"
      },
      "source": [
        "* Train KNN models with different neighbor hyper-parameters\n",
        "* Evaluate KNN models on classification tasks\n",
        "* Tune the number of neighbors and find the optimized one for a specific task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd60d68e-5e9b-4cc7-b0e7-47811b9bd9ba"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91bf5a3d-c979-4acc-970c-5e75445c6d60"
      },
      "source": [
        "First, let's install `seaborn` for visualization tasks and import required libraries for this lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86bd13b5-9d3c-4906-aaa6-150f852bc010"
      },
      "outputs": [],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "# !mamba install -qy pandas==1.3.3 numpy==1.21.2 ipywidgets==7.4.2 scipy==7.4.2 tqdm==4.62.3 matplotlib==3.5.0 seaborn==0.9.0\n",
        "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"."
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91ddc93-2b20-4ecf-abbf-a7423aaa05a3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "# Evaluation metrics related methods\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6234e1a-1f41-4357-bb37-80390dd6f7f4"
      },
      "outputs": [],
      "source": [
        "# Define a random seed to reproduce any random process\n",
        "rs = 123"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13a430a-c218-49e8-855b-201893eddd1f"
      },
      "outputs": [],
      "source": [
        "# Ignore any deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c350ebce-36d5-4967-a970-6961117735b6"
      },
      "source": [
        "## Load and explore the tumor sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96af8def-225a-48f0-adae-1b23fe0eacc0"
      },
      "source": [
        "We first load the dataset `tumor.csv` as a Pandas dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b43fda-0622-4ee7-ad9d-29ff3039fda3"
      },
      "outputs": [],
      "source": [
        "# Read datast in csv format\n",
        "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/tumor.csv\"\n",
        "tumor_df = pd.read_csv(dataset_url)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1457257b-d522-4d6d-9363-62536b23e288"
      },
      "source": [
        "Then, let's quickly take a look at the head of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de416508-6b5b-43cc-8d03-117cd9e30338"
      },
      "outputs": [],
      "source": [
        "tumor_df.head()"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30a88eb1-0e0a-4dd5-8134-c3727aae1d56"
      },
      "source": [
        "And, display its columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28c41e8f-bd26-453e-8fca-075010a4dbac"
      },
      "outputs": [],
      "source": [
        "tumor_df.columns"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31ae1a3b-66b1-48a1-b445-431078e4f00f"
      },
      "source": [
        "Each observation in this dataset contains lab test results about a tumor sample, such as clump or shapes. Based on these lab test results or features, we want to build a classification model to predict if this tumor sample is malicious (cancer) or benign. The target variable `y` is specified in the `Class` column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "017ddeeb-6516-4347-b71d-0a5a6e6f7c87"
      },
      "source": [
        "Then, let's split the dataset into input `X` and output `y`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1918f87d-bee6-4fa8-95e1-d590d8252352"
      },
      "outputs": [],
      "source": [
        "X = tumor_df.iloc[:, :-1]\n",
        "y = tumor_df.iloc[:, -1:]"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "499c1f97-2e76-4230-876f-d8be0ebd2b01"
      },
      "source": [
        "And, we first check the statistics summary of features in `X`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cfc3147-865a-4081-bf2b-7da582c845e3"
      },
      "outputs": [],
      "source": [
        "X.describe()"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74151242-d09b-4684-8336-5743a0d81bd9"
      },
      "source": [
        "As we can see from the above cell output, all features are numeric and ranged between 1 to 10. This is very convenient as we do not need to scale the feature values as they are already in the same range.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fd533f1-80b9-4e10-948f-28e3a5a71801"
      },
      "source": [
        "Next, let's check the class distribution of output `y`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0772454c-4719-4a03-9f46-4d95b6f8337c"
      },
      "outputs": [],
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b49c93e-99f3-40e3-8043-6ed8f8e9be52"
      },
      "outputs": [],
      "source": [
        "y.value_counts().plot.bar(color=['green', 'red'])"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7c99432-5a29-40a2-b401-40074752c33b"
      },
      "source": [
        "We have about 65% benign tumors (`Class = 0`) and 35% cancerous tumors (`Class = 1`), which is not a very imbalanced class distribution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a5fdbae-f358-49e5-8668-8458a21b696f"
      },
      "source": [
        "## Split training and testing datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "270192fa-cc6a-42a2-9636-a6ba379a58c5"
      },
      "outputs": [],
      "source": [
        "# Split 80% as training dataset\n",
        "# and 20% as testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f60b2d01-93a5-4308-a1be-fb645bfcbf51"
      },
      "source": [
        "## Train and evaluate a KNN classifier with the number of neighbors set to 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5a3a2a-b801-4a8c-b972-43f9708a5fd9"
      },
      "source": [
        "Training a KNN classifier is very similar to training other classifiers in `sklearn`, we first need to define a `KNeighborsClassifier` object. Here we use `n_neighbors=2` argument to specify how many neighbors will be used for prediction, and we keep other arguments to be their default values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d09d1a98-0abd-4f6c-8a28-78f7de8f4014"
      },
      "outputs": [],
      "source": [
        "# Define a KNN classifier with `n_neighbors=2`\n",
        "knn_model = KNeighborsClassifier(n_neighbors=2)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42b3f8dd-6793-47ac-b75a-34bfb02cfda8"
      },
      "source": [
        "Then we can train the model with `X_train` and `y_train`, and we use ravel() method to convert the data frame `y_train` to a vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d1ecaeb-a25c-4fb1-84f4-2edc6633594e"
      },
      "outputs": [],
      "source": [
        "knn_model.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4946e670-fda6-44b9-b04f-221e71ea792d"
      },
      "source": [
        "And, we can make predictions on the `X_test` dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cd54089-9581-464f-a3d3-81cd669bd2c9"
      },
      "outputs": [],
      "source": [
        "preds = knn_model.predict(X_test)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcf064e-3dc3-45da-9095-053cf5fc749b"
      },
      "source": [
        "To evaluate the KNN classifier, we provide a pre-defined method to return the commonly used evaluation metrics such as accuracy, recall, precision, f1score, and so on, based on the true classes in the 'y_test' and model predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01b1a603-b05f-4172-9f69-10e889d4a882"
      },
      "outputs": [],
      "source": [
        "def evaluate_metrics(yt, yp):\n",
        "    results_pos = {}\n",
        "    results_pos['accuracy'] = accuracy_score(yt, yp)\n",
        "    precision, recall, f_beta, _ = precision_recall_fscore_support(yt, yp, average='binary')\n",
        "    results_pos['recall'] = recall\n",
        "    results_pos['precision'] = precision\n",
        "    results_pos['f1score'] = f_beta\n",
        "    return results_pos"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87996eb3-7458-4806-b2a8-e78e5e4578d2"
      },
      "outputs": [],
      "source": [
        "evaluate_metrics(y_test, preds)"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1b3bfc8-90fd-4243-aa8c-2d4ca835e63c"
      },
      "source": [
        "We can see that there is a great classification performance on the tumor sample dataset. This means the KNN model can effectively recognize cancerous tumors.\n",
        "Next, it's your turn to try a different number of neighbors to see if we could get even better performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec3792f7-f2e2-417a-adc0-f1b2f04923f3"
      },
      "source": [
        "## Coding exercise: Train and evaluate a KNN classifier with number of neighbors set to 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e8b49c5-5b47-453c-b5fe-2f23934a4ea3"
      },
      "source": [
        "First, define a KNN classifier with KNeighborsClassifier class:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d0b5bb-5e16-4d8b-ad1f-6de63c0857a0"
      },
      "outputs": [],
      "source": [
        "# Type your code here\n"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce90789-f7fd-4562-923a-1ef74ac8a07c"
      },
      "source": [
        "Then train the model with `X_train` and `y_train`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e56ba64-a04c-4688-8fe1-ecf5a0555491"
      },
      "outputs": [],
      "source": [
        "# Type your code here\n"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30247e28-d2d2-41af-86a1-e8a5e60a862c"
      },
      "source": [
        "And, make predictions on `X_test` dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c1b1d54-8802-45c8-a207-37a6b7ee4742"
      },
      "outputs": [],
      "source": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0552cca1-7058-4eec-9ca7-977fca668bb7"
      },
      "source": [
        "At last, you can evaluate your KNN model with provided `evaluate_metrics()` method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87af2c5e-d01e-4c60-82db-7f91fbff4321"
      },
      "source": [
        "<details><summary>Click here for a sample solution</summary>\n",
        "\n",
        "```python\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "preds = model.predict(X_test)\n",
        "evaluate_metrics(y_test, preds)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd614beb-93fd-462f-9050-98fec74847dd"
      },
      "source": [
        "## Tune the number of neighbors to find the optmized one\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ce50ce-fa0e-4061-ab7c-7b416d298710"
      },
      "source": [
        "OK, you may wonder which `n_neighbors` argument may give you the best classification performance. We can try different `n_neighbors` (the K value) and check which `K` gives the best classification performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50547286-7aea-434d-b446-856cdcebbb22"
      },
      "source": [
        "Here we could try K from 1 to 50, and store the aggregated `f1score` for each k into a list.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50d1e09-fcb0-4347-a62e-8cb149b84f6f"
      },
      "outputs": [],
      "source": [
        "# Try K from 1 to 50\n",
        "max_k = 50\n",
        "# Create an empty list to store f1score for each k\n",
        "f1_scores = []"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe92f3e8-5fda-4341-a7f8-7af8af9fed64"
      },
      "source": [
        "Then we will train 50 KNN classifiers with K ranged from 1 to 50.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ba338ff-b784-4436-9d84-b87bf77999f7"
      },
      "outputs": [],
      "source": [
        "for k in range(1, max_k + 1):\n",
        "    # Create a KNN classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # Train the classifier\n",
        "    knn = knn.fit(X_train, y_train.values.ravel())\n",
        "    preds = knn.predict(X_test)\n",
        "    # Evaluate the classifier with f1score\n",
        "    f1 = f1_score(preds, y_test)\n",
        "    f1_scores.append((k, round(f1_score(y_test, preds), 4)))\n",
        "# Convert the f1score list to a dataframe\n",
        "f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n",
        "f1_results.set_index('K')"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c982089-bddc-48f3-ab67-f5a1771ee8ae"
      },
      "source": [
        "This is a long list and different to analysis, so let's visualize the list using a linechart.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "261c5020-2fde-411f-846c-8bebe4136755"
      },
      "outputs": [],
      "source": [
        "# Plot F1 results\n",
        "ax = f1_results.plot(figsize=(12, 12))\n",
        "ax.set(xlabel='Num of Neighbors', ylabel='F1 Score')\n",
        "ax.set_xticks(range(1, max_k, 2));\n",
        "plt.ylim((0.85, 1))\n",
        "plt.title('KNN F1 Score')"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1c9776e-08e5-423d-8e48-a59b1e28b172"
      },
      "source": [
        "As we can see from the F1 score linechart, the best `K` value is 5 with about `0.9691` f1score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f88b9bb-ccb5-4289-9898-7d7d236c2f5a"
      },
      "source": [
        "## Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16bedf00-205f-46bf-aac4-893332bbe515"
      },
      "source": [
        "Great! Now you have learned about and applied the KNN model to solve a real-world tumor type classification problem. You also tuned the KNN to find the best K value. Later, you will continue learning other popular classification models with different structures, assumptions, cost functions, and application scenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12139544-40c3-4271-b66f-e2f8766154dc"
      },
      "source": [
        "## Authors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48fd7da4-60d9-4a06-88bc-533186345ae9"
      },
      "source": [
        "[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d46d827c-e362-4f9c-be90-72b3ce00d089"
      },
      "source": [
        "### Other Contributors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a315b040-ebe9-40f5-8be9-e4ca7df3cbcc"
      },
      "source": [
        "## Change Log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2a3e564-1d87-4941-b916-2bdbd2f47815"
      },
      "source": [
        "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
        "|-|-|-|-|\n",
        "|2021-11-9|1.0|Yan|Created the initial version|\n",
        "|2022-3-29|1.1|Steve Hord|QA Pass|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd7cb51c-d34c-4112-ae01-68a30feddd66"
      },
      "source": [
        "Copyright Â© 2021 IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}